"""
@author: ciacomin
"""

import numpy as np
import pandas as pd
#import glob
import xarray as xr
#from xarray import DataArray

### Figures : maps and altitude maps
import matplotlib as mpl
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
import matplotlib.cm as cm
import matplotlib.colors as colors
from matplotlib.colors import ListedColormap,LinearSegmentedColormap

# pip install mpl-scatter-density
#import mpl_scatter_density # adds projection='scatter_density'

# Map figure
import warnings; warnings.filterwarnings("ignore")
import cartopy.crs as ccrs

crs = ccrs.PlateCarree()

from mpl_toolkits.axes_grid1 import make_axes_locatable

#import cartopy.crs as ccrs
import cartopy.feature as cfeature
#import proplot
from matplotlib import ticker


# Statistics
from scipy import stats

from scipy.constants import g


#%% COLORMAPS
# Prob. colormap 
# "% of extreme events belonging to each WT"
colormap17_pr = [
    "#d9ecff", "#c0dbfa",
    "#9ccaf7", "#69b3f0",
    #"#50a7e6","#3994cc",
    "#2481b3", "#1c7199",
    "#0f6080", "#08515e",
    "#045c5c", "#016754",
    "#0b8054", "#1e9253",
    "#52b041", "#6dbd37",  
    "#87ca2d", "#c6e616", "#feff00"
    ]

prob_colormap = mpl.colors.ListedColormap(colormap17_pr)


# TRENDS
colors_trend =     [
    "#2476b5", #bright
    "#0c4b78", # dark
    
    "#008c69",
    "#005259",
    
 # dark
    "#00cc44",
    "#01802b",

    #"#ffd400", 
    "#ffaa00",
    "#ff7f00",
        
    "#eb1cb7",
    #"#be21cc",
    "#8613bf",
        
    "#6419a6",    #modified
    #"#450a80",
    "#330066"]

trend_colormap = mpl.colors.ListedColormap(colors_trend)

seasonal_colors = [
    # Winter (DJF) - light to dark blue
     "#6497b1", "#005b96",
    # Spring (MAM) - light pink to magenta
    "#fbb4b9", "#f768a1", #"#ae017e",
    # Summer (JJA)- shades of green
    #"#a1d99b", 
    "#41ab5d", "#006d2c",
    # Autumn (SON) - light to dark orange
    #"#fdbe85", 
    "#fd8d3c", "#e6550d",
    
    #"#b3cde3"
]

seasonal_color_trend = mpl.colors.ListedColormap(seasonal_colors)

# SEASONALITY
seasonal_colors_hex = [
    # Winter (DJF) - light to dark blue
    "#6497b1", "#005b96",
    # Spring (MAM) - light pink to magenta
    "#fbb4b9", "#f768a1", "#ae017e",
    # Summer (JJA)- shades of green
    "#a1d99b", "#41ab5d", "#006d2c",   
    # Autumn (SON) - light to dark orange
    "#fdbe85", "#fd8d3c", "#e6550d",

    "#b3cde3"
]

seasonal_colormap = mpl.colors.ListedColormap(seasonal_colors_hex)


#%% OPEN DATA
def ERA5_IVT(path_file, start_time, end_time, domain=None):
    """
    To load IVT data
    Parameters
    ----------
    path_file : string, path for the file
    domain : string, optional
        EU2 or IT . The default is None.
    sel_time : string, optional
        "time1" for 1991-2022 or "time2" for 1985-2019 The default is None.

    Returns
    -------
    TYPE
        DESCRIPTION.

    """
  
    ds = xr.open_mfdataset(path_file)
    variable_list = list(ds.keys())
    print(variable_list)
    # preprocessing 

    if domain == "EU3":
        dset = ds.sel(lat = slice(60,25), lon = slice(-13,35))
    elif domain=="IT":
        dset = ds.sel(lat = slice(48,36), lon = slice(6,19)) # italy
    else :
        dset = ds
        print("All domain")
    

    dset = dset.sel(time=slice(str(start_time), str(end_time)))
        
    try :
        print("is the first variable time bounds and the second the main data? if not check")
        Time_Bounds = dset[variable_list[0]].values
        Main_data = dset[variable_list[1]].values
    except :
        print("check the dataset's variable")
        return 0
        
    Time_data = dset["time"].values
    Xlat = dset["lat"].values
    Xlong = dset["lon"].values
    
    return Main_data, Time_data, Xlat, Xlong, Time_Bounds


#%% DATAFRAME MANIPULATIONS
def dataframe_cut_xlsx(path_xlsx_file, first_year, last_year, exclude_last_row=False):
    # function to cut a selected dataset from a bigger one
    # check 
    # - first column is the column of times
    # - the format of the dates
    data_raw= pd.read_excel(path_xlsx_file)
    data_tmp = data_raw
    
    if exclude_last_row == True:
        data_tmp = data_raw.iloc[:-1]
        
    label_first_column = data_tmp.columns[0] #get the label of the first column

    data = data_tmp.rename(columns={ label_first_column : "Time"}) #change the label
    
    data['Time'] = pd.to_datetime(data['Time'])
    #data['Time'] = data['Time'].apply(pd.to_datetime)
    # do the time mask
    time_mask = (data['Time'].dt.year >= first_year) & \
                (data['Time'].dt.year <= last_year)
    # select the data
    data[time_mask]
    choseInd = [ind for ind in data[time_mask].index]
    
    df_select = data.loc[choseInd]
    
    return data_raw, df_select

def dataframe_cut_xlsx_sheet(path_xlsx_file, sheet_name, first_year, last_year, exclude_last_row=False):
    # same as dataframe_cut_xlsx but for a specific sheet
    
    data_raw= pd.read_excel(path_xlsx_file, sheet_name=sheet_name)
    data_tmp = data_raw
    
    if exclude_last_row == True:
        data_tmp = data_raw.iloc[:-1]
        
    label_first_column = data_tmp.columns[0] #get the label of the first column

    data = data_tmp.rename(columns={ label_first_column : "Time"}) #change the label
    
    data['Time'] = pd.to_datetime(data['Time'])
    #data['Time'] = data['Time'].apply(pd.to_datetime)
    # do the time mask
    time_mask = (data['Time'].dt.year >= first_year) & \
                (data['Time'].dt.year <= last_year)
    # select the data
    data[time_mask]
    choseInd = [ind for ind in data[time_mask].index]
    
    df_select = data.loc[choseInd]
    
    return data_raw, df_select

def dataframe_cut(path_csv_file, first_year, last_year):
    # same as dataframe_cut_xlsx but for a csv file
    
    data_raw= pd.read_csv(path_csv_file)
    label_first_column = data_raw.columns[0] #get the label of the first column

    data = data_raw.rename(columns={ label_first_column : "Time"}) #change the label
    
    data['Time'] = pd.to_datetime(data['Time'])
    #data['Time'] = data['Time'].apply(pd.to_datetime)
    # do the time mask
    time_mask = (data['Time'].dt.year >= first_year) & \
                (data['Time'].dt.year <= last_year)
    # select the data
    data[time_mask]
    choseInd = [ind for ind in data[time_mask].index]
    
    df_select = data.loc[choseInd]
    
    return data_raw, df_select


def dataframe_extremes_xlsx(pd_dataframe, label_col_extreme):
    # select the entries for whom "label_col_extreme" is True
    
    df = pd_dataframe
    #label_first_column = df.columns[-2]
    df_select = df.loc[df[label_col_extreme] == True]
    return df_select

def add_pr_max_column(dataset, idx_first_c, idx_last_c):
    idx_stop = idx_last_c + 1
    df_cutted = dataset.iloc[:, idx_first_c: idx_stop]
    pr_max_c = df_cutted.max(axis=1)
    dataset["PrMax"]=pr_max_c
    #new_df = dataset.insert[1, "Pr Max", pr_max_c]
    
    return dataset

#%% COMPOSITES
def divide_dates_by_index(list_of_dates, list_of_indices, number_indices):
    # Initialize a list of empty lists
    divided_dates = [[] for _ in range(number_indices)]
    
    # Iterate through dates and indices
    for date, index in zip(list_of_dates, list_of_indices):
        # Add the date to the list corresponding to the index
        divided_dates[index].append(date)
    
    return divided_dates

def single_SOM_map_composite_with_ref_nearest(data_values_som, time_values_som, data_values, time_values, cluster_dates_list):
    """
    Generate composite of data variable for the differents nodes for a single SOM

    Parameters
    ----------
    data_values_som : .npy
        Values of train data or test data.
    time_values_som : .npy
        Time values of train data or test data.
    data_values : TYPE
        Values of given variable.
    time_values : TYPE
        Time values of given variable.
    cluster_dates_list : list of dates

    Returns
    -------
    maps_composite : list of maps
        maps value of composites of given variable.

    """

    maps_composite = [None for _ in range(len(cluster_dates_list)) ] 
    nx = len(data_values[0])
    ny = len(data_values[0,0])
    
    for j in range(len(cluster_dates_list)):
        list_map_temp = []
        for k in range(len(cluster_dates_list[j])):
            indx = np.where(time_values[:].astype('datetime64[D]')==cluster_dates_list[j][k].astype('datetime64[D]'))[0]
            #indx = np.where(time_values[:]==cluster_dates_list[i][j][k], "nearest")[0][0]
            
            #print(cluster_dates_list[0][0][k])
            #print(time_values[indx])
            #print("")
            list_map_temp += [data_values[indx]] 
            print(time_values[indx])
            print(cluster_dates_list[j][k])
            
        list_map_mean = np.mean(list_map_temp, axis=0)
        print("shape")
        print(list_map_mean.shape)
        #maps_composite[i][j] = list_map_mean[0,:,:]
       
        try:
            maps_composite[j]=np.reshape(list_map_mean,(nx,ny))
        except ValueError:
            maps_composite[j]=np.zeros((nx,ny))
        #print(len(list_map_temp))

    return maps_composite

def single_generate_SOM_composites_Z500_mslp(data_lon, data_lat, data_shaded, data_contour, som_col, som_row, name_som, folderpath, pattern_list, test_or_all=None, chosen_map="RdYlBu_r"):
    # Z500 shaded
    # mslp contour
    datacrs = ccrs.PlateCarree()
    #wt_list = [1, 3, 5, 2, 4, 6]
      
    """
    #You will set this to the dimensions of the SOM.  ## DIM OF SOMS
    fig, axs = plt.subplots(nrows=som_row,ncols=som_col, 
                            subplot_kw={'projection':ccrs.LambertConformal(central_longitude=lon.mean(), central_latitude=lat.mean(), standard_parallels=(30, 60))},
                            figsize=(30, 15),facecolor='white') 
    """
    #You will set this to the dimensions of the SOM.  ## DIM OF SOMS
    fig, axs = plt.subplots(nrows=som_row,ncols=som_col, 
                            subplot_kw={'projection': ccrs.PlateCarree()},
                            figsize=(40, 16),facecolor='white') 
    axs=axs.flatten()
    for k in range(len(data_shaded)): # for on the nodes
        # to check
        # Z500
        lev_start = 533 # dam
        #print(lev_start)             
        lev_stop = 592 # dam
        step = 3 # generalmente è 30
        #print(lev_stop)
        n_cmap = int((lev_stop - lev_start) / step)
        cmap = plt.cm.get_cmap(chosen_map, n_cmap)
        levs = np.arange(lev_start, lev_stop, step)
        norm = mpl.colors.BoundaryNorm(levs, cmap.N)
        
        cs2=axs[k].contourf(data_lon, data_lat, data_shaded[k]/10,
                          n_cmap, cmap=cmap, norm=norm, levels=levs, extend='both', transform = ccrs.PlateCarree())
        
        # MSLP
        levels = np.arange(950, 1050, 3) # label height
        contour = axs[k].contour(data_lon, data_lat, data_contour[k], levels, colors='k', transform = ccrs.PlateCarree(), linewidths=1.8)
        plt.clabel(contour, inline=True, inline_spacing=4, fontsize=10, fmt='%1.0f') 
   
        axs[k].set_extent([data_lon[0], data_lon[-1], data_lat[0], data_lat[-1]], ccrs.PlateCarree())
        
        axs[k].coastlines(color="#3f0f4f")
        axs[k].add_feature(cfeature.BORDERS, linestyle="--", color="#5c1b72") 

        # Title each subplot 
        #axs[k].set_title('Node:'+str(k+1) + " Freq:" + str(frequencies[k,i]), fontsize=18)
        axs[k].set_title('WT' + str(pattern_list[k]), fontsize=28)

        plt.tight_layout()
        fig.subplots_adjust(bottom=0.25, top=0.9, left=0.05, right=0.6,
                    wspace=0.05, hspace=0.25)
    
    cbar_ax = fig.add_axes([0.08, 0.2, 0.5, 0.02])
    #cbar=fig.colorbar(cs2,cax=cbar_ax, ticks = np.arange(lev_start, np.abs(lev_start)+lev_step, lev_step*2),orientation='horizontal')
    #cbar=fig.colorbar(cs2,cax=cbar_ax, ticks = levs,orientation='horizontal')
    cbar = mpl.colorbar.ColorbarBase(cbar_ax, cmap=cmap, norm=norm,
                                 spacing='proportional', ticks=levs, boundaries=levs, format='%1i',  orientation='horizontal')
    
    str_variable = r"$Z_{500}$"
    unit_variable = "dam"
    cbar.set_label(str_variable + " (" + unit_variable + ")", fontsize=26)
    cbar.ax.tick_params(labelsize=24)

    #plt.suptitle('Composites of Z500 (shaded) and mSLP (contour). ' + pr_dataset_str + ",  Master SOM of " + som_variables_str, x= 0.33 ,fontsize=27)   
    #plt.savefig(folderpath + name_som + '_' + 'Composites_Z500_mSLP_'  + test_or_all + '.png', bbox_inches='tight')
    #plt.savefig(folderpath + name_som + '_' + 'Composites_Z500_mSLP_'  + test_or_all + '.svg', bbox_inches='tight')
    plt.show()
    
def single_generate_SOM_composites_Z500_mslp_it(data_lon, data_lat, data_shaded, data_contour, som_col, som_row, name_som, folderpath, pattern_list, test_or_all=None, chosen_map="RdYlBu_r"):
    # Z500 shaded
    # mslp contour
    datacrs = ccrs.PlateCarree()
    #wt_list = [1, 3, 5, 2, 4, 6]
      
    """
    #You will set this to the dimensions of the SOM.  ## DIM OF SOMS
    fig, axs = plt.subplots(nrows=som_row,ncols=som_col, 
                            subplot_kw={'projection':ccrs.LambertConformal(central_longitude=lon.mean(), central_latitude=lat.mean(), standard_parallels=(30, 60))},
                            figsize=(30, 15),facecolor='white') 
    """
    #You will set this to the dimensions of the SOM.  ## DIM OF SOMS
    fig, axs = plt.subplots(nrows=som_row,ncols=som_col, 
                            subplot_kw={'projection': ccrs.PlateCarree()},
                            figsize=(40, 20),facecolor='white') 
    axs=axs.flatten()
    for k in range(len(data_shaded)): # for on the nodes
        # to check
        # Z500
        lev_start = 533 # dam
        #print(lev_start)             
        lev_stop = 592 # dam
        step = 3 # generalmente è 30
        #print(lev_stop)
        n_cmap = int((lev_stop - lev_start) / step)
        cmap = plt.cm.get_cmap(chosen_map, n_cmap)
        levs = np.arange(lev_start, lev_stop, step)
        norm = mpl.colors.BoundaryNorm(levs, cmap.N)
        
        cs2=axs[k].contourf(data_lon, data_lat, data_shaded[k]/10,
                          n_cmap, cmap=cmap, norm=norm, levels=levs, extend='both', transform = ccrs.PlateCarree())
        
        # MSLP
        levels = np.arange(950, 1050, 3) # label height
        contour = axs[k].contour(data_lon, data_lat, data_contour[k], levels, colors='k', transform = ccrs.PlateCarree(), linewidths=1.5)
        plt.clabel(contour, inline=True, inline_spacing=-13, fontsize=15, fmt='%1.0f') 
   
        axs[k].set_extent([2, 19, 50, 35], ccrs.PlateCarree())        
        
        axs[k].coastlines(color="#3f0f4f")
        axs[k].add_feature(cfeature.BORDERS, linestyle="--", color="#5c1b72") 

        # Title each subplot 
        #axs[k].set_title('Node:'+str(k+1) + " Freq:" + str(frequencies[k,i]), fontsize=18)
        axs[k].set_title('WT' + str(pattern_list[k]), fontsize=28)

        plt.tight_layout()
        fig.subplots_adjust(bottom=0.25, top=0.9, left=0.05, right=0.6,
                    wspace=0.05, hspace=0.25)
    
    cbar_ax = fig.add_axes([0.08, 0.2, 0.5, 0.02])
    
    #cbar=fig.colorbar(cs2,cax=cbar_ax, ticks = np.arange(lev_start, np.abs(lev_start)+lev_step, lev_step*2),orientation='horizontal')
    #cbar=fig.colorbar(cs2,cax=cbar_ax, ticks = levs,orientation='horizontal')
    cbar = mpl.colorbar.ColorbarBase(cbar_ax, cmap=cmap, norm=norm,
                                 spacing='proportional', ticks=levs, boundaries=levs, format='%1i',  orientation='horizontal')
    
    str_variable = r"$Z_{500}$"
    unit_variable = "dam"
    cbar.set_label(str_variable + " (" + unit_variable + ")", fontsize=26)
    cbar.ax.tick_params(labelsize=24)

    #plt.suptitle('Composites of Z500 (shaded) and mSLP (contour). ' + pr_dataset_str + ",  Master SOM of " + som_variables_str, x= 0.33 ,fontsize=27)   
    #plt.savefig(folderpath + name_som + '_' + 'Composites_Z500_mSLP_'  + test_or_all + 'IT.png', bbox_inches='tight')
    #plt.savefig(folderpath + name_som + '_' + 'Composites_Z500_mSLP_'  + test_or_all + 'IT.svg', bbox_inches='tight')
    plt.show()
    
def single_generate_SOM_composites_Z500_TCWV_IVT(z_lon, z_lat, TCWV_lon, TCWV_lat, IVT_lon, IVT_lat, data_shaded, data_contour, ivte, ivtn, som_col, som_row, name_som, folderpath, pattern_list, test_or_all=None, chosen_map= "RdYlBu_r"):
    # Z500 contour
    # TCWV shaded lighter
    # ivt arrows
    #wt_list = [1, 3, 5, 2, 4, 6]
    
    datacrs = ccrs.PlateCarree()
      
    """
    #You will set this to the dimensions of the SOM.  ## DIM OF SOMS
    fig, axs = plt.subplots(nrows=som_row,ncols=som_col, 
                            subplot_kw={'projection':ccrs.LambertConformal(central_longitude=lon.mean(), central_latitude=lat.mean(), standard_parallels=(30, 60))},
                            figsize=(30, 15),facecolor='white') 
    """
    #You will set this to the dimensions of the SOM.  ## DIM OF SOMS
    fig, axs = plt.subplots(nrows=som_row,ncols=som_col, 
                            subplot_kw={'projection': ccrs.PlateCarree()},
                            figsize=(40, 20),facecolor='white') 
    axs=axs.flatten()
    for k in range(len(data_contour)): # for on the nodes
        # to check
        # Z500
        lev_start = 5150
        #print(lev_start)             
        lev_stop = 5880
        step = 30 # generalmente è 30
        levs = np.arange(lev_start, lev_stop, step)
    
        contour = axs[k].contour(z_lon, z_lat, data_contour[k], levs, colors='teal', transform = ccrs.PlateCarree(), linewidths=1.5)
        plt.clabel(contour, inline=True, fontsize=10, fmt='%1.0f') 
   
        # TCWV
        lev_start = 0
        #print(lev_start)             
        lev_stop = 31
        step = 2 # generalmente è 30
        #print(lev_stop)
        n_cmap_2 = int((lev_stop - lev_start) / step)
        cmap_2 = plt.cm.get_cmap("RdYlBu_r", n_cmap_2)
        bounds_2 = np.arange(lev_start, lev_stop, step)
        
        norm_2 = mpl.colors.BoundaryNorm(bounds_2, cmap_2.N)
        
        cs2=axs[k].contourf(TCWV_lon, TCWV_lat, data_shaded[k],
                          n_cmap_2, cmap=cmap_2, norm=norm_2, levels=bounds_2, extend='both', transform = ccrs.PlateCarree())
    
        axs[k].set_extent([2, 19, 50, 35], ccrs.PlateCarree())

        axs[k].coastlines()
        axs[k].add_feature(cfeature.BORDERS, linestyle="--") 
        
        #axs[k].streamplot(lon, lat, ivte[i][k], ivtn[i][k], density=0.5, color="white")
        #axs[k].quiver(lon, lat, ivte[i][k], ivtn[i][k])
        
        # Calcola la magnitudine del vettore IVT
        ivt_magnitude = np.sqrt(ivte[k]**2 + ivtn[k]**2)
        
        #MASK
        """
        # se vuoi utilizzare la maschera
        mask = ivt_magnitude > 100
        ivte_filtered = np.ma.masked_where(~mask, ivte[i][k])
        ivtn_filtered = np.ma.masked_where(~mask, ivtn[i][k])
        ivt_magnitude_filtered = np.ma.masked_where(~mask, ivt_magnitude)
        quiver = axs[k].quiver(lon, lat, ivte_filtered, ivtn_filtered, ivt_magnitude_filtered, 
                               cmap=cmap_custom, norm=norm_custom, transform=ccrs.PlateCarree(), angles='xy', scale_units='xy', scale=1.,headwidth=1, density=0.5)
        
        """
        # Skip
        n_skip= 6
        skip = (slice(None, None, n_skip), slice(None, None, n_skip))
        
        # IVT Colormaps
        lev_start = 0          
        lev_stop = 401
        step = 20
        #n_cmap = int((lev_stop - lev_start) / step)
        #cmap = plt.cm.get_cmap(chosen_map, n_cmap)
        bounds = np.arange(lev_start, lev_stop, step)
        #norm = mpl.colors.BoundaryNorm(bounds, cmap.N)
        
        # Disegna il quiver plot con i colori personalizzati
        # mettendo cmap = chosenmap e ivt_magnitude[skip],
        quiver = axs[k].quiver(IVT_lon[::n_skip], IVT_lat[::n_skip], ivte[k][skip], ivtn[k][skip], color="darkgray", transform=ccrs.PlateCarree(),
                   headwidth=4, scale=200, headlength=5, width=0.08, units="xy", edgecolor="k", linewidths=0.6)
        #quiver = axs[k].quiver(lon, lat, ivte_filtered, ivtn_filtered, ivt_magnitude_filtered, 
                               #cmap=cmap_custom, norm=norm_custom, transform=ccrs.PlateCarree(), angles='xy', scale_units='xy', scale=1.,headwidth=1, density=0.5)

        # Title each subplot 
        #axs[k].set_title('Node:'+str(k+1) + " Freq:" + str(frequencies[k,i]), fontsize=18)
        axs[k].set_title('WT' + str(pattern_list[k]), fontsize=25)

        plt.tight_layout()
        fig.subplots_adjust(bottom=0.25, top=0.9, left=0.05, right=0.6,
                    wspace=0.05, hspace=0.25)
    
    # Colorbar per il quiver plot
    #IVT
    #cbar_ax = fig.add_axes([0.08, 0.1, 0.5, 0.02]) #horizontal
    #cbar_ax = fig.add_axes([0.61, 0.3, 0.01, 0.55])
    #cbar = mpl.colorbar.ColorbarBase(cbar_ax, cmap=cmap, norm=norm,
    #                                  spacing='proportional', ticks=bounds, boundaries=bounds, format='%1i', orientation='vertical')
    #cbar.set_label(r'IVT [$kg \cdot m^{-1} \cdot s^{-1}$)]', fontsize=22)
    
    # Aggiungi le frecce di esempio
    arrow_positions = [1.2, 1.15, 1.1, 1.05]  # Posizioni verticali relative per le frecce
    arrow_magnitudes = [100, 200, 300, 400]   # Magnitudini corrispondenti
    for pos, magnitude in zip(arrow_positions, arrow_magnitudes):
        axs[k].quiverkey(
            quiver, X=0.75, Y=pos, U=magnitude,
            label=f'{magnitude} kg/m/s',
            labelpos='E', transform=axs[k].transAxes, fontproperties={'size':18}
            )
    
    
    # SHADED
    cbar2_ax = fig.add_axes([0.08, 0.2, 0.5, 0.02])
    cbar2 = mpl.colorbar.ColorbarBase(cbar2_ax, cmap=cmap_2, norm=norm_2,
                                      spacing='proportional', ticks=bounds_2, boundaries=bounds_2, format='%0.1f', orientation='horizontal')
    cbar2.set_label(r'TCWV [$kg \cdot m^{-2}$]', fontsize=24)
    cbar2.ax.tick_params(labelsize=22)
    
    #plt.suptitle('Composites of Z500 (contour), TCWV (shaded) and IVT (arrows). ' + pr_dataset_str + ", Master SOM of " + som_variables_str, x= 0.33 ,fontsize=27)   
    #plt.savefig(folderpath + 'Composites_Z500_TCWV_IVT_' +names_som[i]+ '_' + test_or_all + '_v2.png', bbox_inches='tight')
    #plt.savefig(folderpath + name_som + '_' + 'Composites_Z500_TCWV_IVT_'  + test_or_all + '.png', bbox_inches='tight')
    #plt.savefig(folderpath + name_som + '_' + 'Composites_Z500_TCWV_IVT_'  +test_or_all + '.svg', bbox_inches='tight')
    plt.show()
    
#%% SEASONALITY
month_str = ["Jan", "Feb", "Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sep", "Oct", "Nov", "Dec"]

def func(pct, allvals):
    absolute = int(pct/100.*np.sum(allvals))
    return "{:.1f}%\n({:d})".format(pct, absolute)

    
#%% TREND
def linear_trend(x, y):
    """
    Computes the linear trend of the given data.
    
    Parameters:
    - x: array-like, independent variable (e.g., year)
    - y: array-like, dependent variable (e.g., count)
    
    Returns:
    - m: slope of the line
    - q: intercept
    - y_fit: estimated values for the linear trend
    """
    m, q = np.polyfit(x, y, 1)
    y_fit = m * x + q  
    return m, q, y_fit

def get_season(date):
    month = date.month
    if month in [12, 1, 2]:
        return 'DJF'
    elif month in [3, 4, 5]:
        return 'MAM'
    elif month in [6, 7, 8]:
        return 'JJA'
    else:
        return 'SON'
        return 'JJA'
    else:
        return 'SON'
