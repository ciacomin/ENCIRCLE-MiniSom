import os

os.chdir('C:\\Users\\Criss\\Documents\\Lavoro\\Assegno 2024_2025\\Codici')

#Imports 
import xarray as xr
import numpy as np
import pandas as pd
import warnings
import minisom
import pickle
from minisom import asymptotic_decay
import cartopy.mpl.ticker as cticker
from cartopy.util import add_cyclic_point
from mpl_toolkits.mplot3d import Axes3D
import matplotlib as mpl
from numpy import savetxt
from numpy import loadtxt
import cartopy
import cartopy.crs as ccrs
import cartopy.feature as cfeature
import glob
import matplotlib.pyplot as plt
import os
from itertools import product
import winsound
from datetime import date

#Functions Used in the Code
def getList(dict):
    list = []
    for key in dict.keys():
        list.append(key)
        
    return list
def sammon(x, n, display = 2, inputdist = 'raw', maxhalves = 20, maxiter = 500, tolfun = 1e-9, init = 'default'):

    import numpy as np 
    from scipy.spatial.distance import cdist

    """Perform Sammon mapping on dataset x
    y = sammon(x) applies the Sammon nonlinear mapping procedure on
    multivariate data x, where each row represents a pattern and each column
    represents a feature.  On completion, y contains the corresponding
    co-ordinates of each point on the map.  By default, a two-dimensional
    map is created.  Note if x contains any duplicated rows, SAMMON will
    fail (ungracefully). 
    [y,E] = sammon(x) also returns the value of the cost function in E (i.e.
    the stress of the mapping).
    An N-dimensional output map is generated by y = sammon(x,n) .
    A set of optimisation options can be specified using optional
    arguments, y = sammon(x,n,[OPTS]):
       maxiter        - maximum number of iterations
       tolfun         - relative tolerance on objective function
       maxhalves      - maximum number of step halvings
       input          - {'raw','distance'} if set to 'distance', X is 
                        interpreted as a matrix of pairwise distances.
       display        - 0 to 2. 0 least verbose, 2 max verbose.
       init           - {'pca', 'cmdscale', random', 'default'}
                        default is 'pca' if input is 'raw', 
                        'msdcale' if input is 'distance'
    The default options are retrieved by calling sammon(x) with no
    parameters.
    File        : sammon.py
    Date        : 18 April 2014
    Authors     : Tom J. Pollard (tom.pollard.11@ucl.ac.uk)
                : Ported from MATLAB implementation by 
                  Gavin C. Cawley and Nicola L. C. Talbot
    Description : Simple python implementation of Sammon's non-linear
                  mapping algorithm [1].
    References  : [1] Sammon, John W. Jr., "A Nonlinear Mapping for Data
                  Structure Analysis", IEEE Transactions on Computers,
                  vol. C-18, no. 5, pp 401-409, May 1969.
    Copyright   : (c) Dr Gavin C. Cawley, November 2007.
    This program is free software; you can redistribute it and/or modify
    it under the terms of the GNU General Public License as published by
    the Free Software Foundation; either version 2 of the License, or
    (at your option) any later version.
    This program is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU General Public License for more details.
    You should have received a copy of the GNU General Public License
    along with this program; if not, write to the Free Software
    Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
    """

    # Create distance matrix unless given by parameters
    if inputdist == 'distance':
        D = x
        if init == 'default':
            init = 'cmdscale'
    else:
        D = cdist(x, x)
        if init == 'default':
            init = 'pca'

    if inputdist == 'distance' and init == 'pca':
        raise ValueError("Cannot use init == 'pca' when inputdist == 'distance'")

    if np.count_nonzero(np.diagonal(D)) > 0:
        raise ValueError("The diagonal of the dissimilarity matrix must be zero")

    # Remaining initialisation
    N = x.shape[0]
    scale = 0.5 / D.sum()
    D = D + np.eye(N)     
    if np.count_nonzero(D<=0) > 0:
        raise ValueError("Off-diagonal dissimilarities must be strictly positive")   

    Dinv = 1 / D
    if init == 'pca':
        [UU,DD,_] = np.linalg.svd(x)
        y = UU[:,:n]*DD[:n] 
    elif init == 'cmdscale':
        from cmdscale import cmdscale
        y,e = cmdscale(D)
        y = y[:,:n]
    else:
        y = np.random.normal(0.0,1.0,[N,n])
    one = np.ones([N,n])
    d = cdist(y,y) + np.eye(N)
    dinv = 1. / d
    delta = D-d 
    E = ((delta**2)*Dinv).sum() 

    # Get on with it
    for i in range(maxiter):

        # Compute gradient, Hessian and search direction (note it is actually
        # 1/4 of the gradient and Hessian, but the step size is just the ratio
        # of the gradient and the diagonal of the Hessian so it doesn't
        # matter).
        delta = dinv - Dinv
        deltaone = np.dot(delta,one)
        g = np.dot(delta,y) - (y * deltaone)
        dinv3 = dinv ** 3
        y2 = y ** 2
        H = np.dot(dinv3,y2) - deltaone - np.dot(2,y) * np.dot(dinv3,y) + y2 * np.dot(dinv3,one)
        s = -g.flatten(order='F') / np.abs(H.flatten(order='F'))
        y_old    = y

        # Use step-halving procedure to ensure progress is made
        for j in range(maxhalves):
            s_reshape = np.reshape(s, (-1,n),order='F')
            y = y_old + s_reshape
            d = cdist(y, y) + np.eye(N)
            dinv = 1 / d
            delta = D - d
            E_new = ((delta**2)*Dinv).sum()
            if E_new < E:
                break
            else:
                s = 0.5*s

        # Bomb out if too many halving steps are required
        if j == maxhalves-1:
            print('Warning: maxhalves exceeded. Sammon mapping may not converge...')

        # Evaluate termination criterion
        if abs((E - E_new) / E) < tolfun:
            if display:
                print('TolFun exceeded: Optimisation terminated')
            break

        # Report progress
        E = E_new
        if display > 1:
            print('epoch = %d : E = %12.10f'% (i+1, E * scale))

    if i == maxiter-1:
        print('Warning: maxiter exceeded. Sammon mapping may not have converged...')

    # Fiddle stress to match the original Sammon paper
    E = E * scale
    
    return [y,E]

# COLORMAP
new_colormap = [
    "#ecf5ff",     # celeste pi√π chiaro
   # "#d9ecff",    #new
    "#a1cff7",    #new
    "#5ca8e5",    #new
    "#2476b5",    #new
    "#0c4b78",    #new
    "#00334c",    #new
    "#005259",    #new
    "#008c69",    #new
    "#00cc44",
    "#95ff00",
    "#ffff00",
    "#ffd400",
    "#ffaa00",
    "#ff7f00",
    "#ff5500",
    "#ff2a00",
    "#f20c1f",
    "#cc1461",
    "#eb1cb7",    #new
    "#be21cc",
    "#8613bf",
    "#5f19a6",
    "#330067",    #new
]

precip_colormap = mpl.colors.ListedColormap(new_colormap)

#from previous file
z500_factor = 0.09986427280939095
mslp_factor = 1.2766742595638787

#%% Dataset and Export location
#State the path where the file is located. This will be the same path used in MiniSOM Tutorial Step #1
PATH ="C:/Users/Criss/Documents/Lavoro/Assegno 2024_2025/Codici/SOM/" #This is the path where the data files
folderpath = 'C:/Users/Criss/Documents/Lavoro/Assegno 2024_2025/Codici/SOM/SOMs_output/'  #The output SOMs will be stored in a seperate folder. This will need to be changed to the User's specific path and folder name
# Z500
#data_train = np.load(PATH + 'Z500_som_data_train_All_CAT_anomalies.npy')
#time_values = np.load(PATH +'Z500_som_time_data__All_CAT_anomalies.npy')
#z_raw = xr.open_dataset(PATH + 'Z500_som_raw_All_CAT_anomalies.nc')
#z_mean_array = np.load(PATH +'Z500_mean_array_All_CAT_anomalies.npy')
#norm_factor = z500_factor # CHANGE

# MSLP
data_train = np.load(PATH + 'MSLP_som_data_train_All_CAT_anomalies.npy')
time_values = np.load(PATH +'MSLP_som_time_data__All_CAT_anomalies.npy')
z_raw = xr.open_dataset(PATH + 'MSLP_som_raw_All_CAT_anomalies.nc')
z_mean_array = np.load(PATH +'MSLP_mean_array_All_CAT_anomalies.npy')
norm_factor = mslp_factor

print(data_train.shape)
len_datatrain = len(data_train[0])

# variable loading
#z_values = z_raw['Z'].values
#z_SOM = z_raw['Z']
lon = z_raw['lon'].values
lat = z_raw['lat'].values
nx = int((z_raw['lat'].size))
ny = int((z_raw['lon'].size))
ndays =int((z_raw['time'].size))

today = date.today()


#%%
#You want to change these to the settings that you would like. 
som_col = 2
som_row = 2
min_som = min(som_col, som_row)
#x= 3 #columns
#y= 4 #row
input_length = len_datatrain #This is value is the the length of the latitude X longitude. It is the second value in the data_train.shape step. 
sigma = min_som -1        #The sigma value must be y-1. 
learning_rate = 0.0005  #Learning Rate 
qerror_list = []
q_win = 100000.

som_names = "SOM_MSLP_All_CAT_" + str(today) + "_" + str(som_col) + "by" + str(som_row) + "_LR" + str(learning_rate) + "_sig" + str(sigma) + "_n_"
print(som_names)
#%%
for i in range(10):   #The number of SOMs that will be generated. 
    # initialize random weights
    era5_hourly_som1 = minisom.MiniSom(som_row, som_col, input_len = input_length, sigma = sigma, learning_rate=learning_rate, neighborhood_function='gaussian', decay_function = asymptotic_decay)
    era5_hourly_som1.random_weights_init(data_train)
    # train som
    era5_hourly_som1.train(data_train, num_iteration=100000,random_order=True, verbose=True)
    q_error = era5_hourly_som1.quantization_error(data_train)
    
    #Add the details of the SOM settings into the name of the file so that you know what the SOM is showing.
    with open(folderpath + som_names +str(i+1)+'.p', 'wb') as outfile: #this is how you save the file, the str(i) is a unique name
        pickle.dump(era5_hourly_som1, outfile)
    weights = era5_hourly_som1._weights
    qerror_list += [q_error]
    i+=1
    if q_error < q_win:
        q_win = q_error
        win_weights = era5_hourly_som1
        
print('\007')

#%%
#Set the SOM Columns and the Rows 
#som_col = 6
#som_row = 4
#k_mul = max(som_col, som_row)
#print(k_mul)

names = ([os.path.splitext(os.path.split(x)[-1])[0] for x in glob.glob(folderpath + som_names + '*')]) #this might be different for you

#but this is just grabbing the first few characters of my names of my file (see above how I named them, for example som_8)

filepaths = glob.glob(folderpath + som_names + '*')  #this is showing the path and the given file

print(names)

#%%
for path, name in zip(filepaths, names):
    with open (path, 'rb') as f:
        file = pickle.load(f) #This is loading every single som in that location
        frequencies = file.activation_response(data_train) #this is grabbing each freq
        q_error = round(file.quantization_error(data_train),3) #this is grabbing every q error out to 3 decimal places
        topo_error = round(file.topographic_error(data_train),3) #this is grabbing ever topographic error out to 3 decimal places
        plt.figure(figsize=(10,8))
        cs = plt.pcolormesh(frequencies, cmap='Blues')
        plt.title(name + ' ' + 'Freq.,' + ' ' + 'QE =' + ' ' f"{q_error}" + ' ' + 'TE =' + ' ' f"{topo_error}", fontsize=12)

        #in the title, I am plotting every q error and topo error from each som. You need to have the f" in front and whatever variable in {}
        #And this ' ' represents a space in the title
        plt.colorbar(cs)
        plt.ylim(som_row,0) # Change the 3 to whatever size SOM you have (this is the 2nd number)
        plt.tight_layout()
        plt.savefig(folderpath + 'frequencies_'+name+'.png') #I am saving the outputs as a png file in the same file path and giving it the name of each SOM
        
        plt.show()
        
        [y,E] = sammon(file.get_weights().reshape(som_col*som_row, input_length),2,display=1)

            # Plot Sammon map nodes
        plt.figure(figsize=(10,8))
        plt.scatter(y[:,0], y[:,1], s=20, c='black', marker='o')

            # Add lines between nodes
        mslp = np.reshape(y,(som_row,som_col,2))
        len_x, len_y, len_z = mslp.shape

        # add vertical lines
        for i in range(len_x-1):
            for j in range(len_y):
                plt.plot(mslp[i:i+2,j,0],mslp[i:i+2,j,1],c='black')

        # add horizontal lines
        for i in range(len_x):
            for j in range(len_y-1):
                plt.plot(mslp[i,j:j+2,0],mslp[i,j:j+2,1],c='black')  

        plt.xticks([])
        plt.yticks([])
        plt.title(name, fontsize=12)
        plt.savefig(folderpath + 'sammonplot_'+name+'.png') #I am saving the outputs as a png file in the same file path and giving it the name of each SOM

        plt.show()
        
print('\007')
print('\007')
        
#%%
for path, name in zip(filepaths, names):
    with open (path, 'rb') as f:
        file = pickle.load(f) #This is loading every single som in that location
        frequencies = file.activation_response(data_train) #this is grabbing each freq
        print(frequencies.shape)
        print(frequencies)
        print(frequencies[0,0])
        
#%%
for path, name in zip(filepaths, names):
    with open (path, 'rb') as f:
        som = pickle.load(f)
        weights = som._weights

        #Need to create a new dictionary for the new data
        keys = [i for i in product(range(som_row), range(som_col))]  ## DIM OF SOMS
        winmap = {key: [] for key in keys}

        for i, x in enumerate(data_train):
            winmap[som.winner(x)].append(i)
            som_keys = getList(winmap)
        frequencies = som.activation_response(data_train)
        datacrs = ccrs.PlateCarree()
        
        #You will set this to the dimensions of the SOM.  ## DIM OF SOMS
        fig, axs = plt.subplots(nrows=som_row,ncols=som_col, 
                                subplot_kw={'projection':ccrs.LambertConformal(central_longitude=lon.mean(), central_latitude=lat.mean(), standard_parallels=(30, 60))},
                                figsize=(30, 15),facecolor='white') 
        
        #You will set this to the dimensions of the SOM.  ## DIM OF SOMS
        fig, axs = plt.subplots(nrows=som_row,ncols=som_col, 
                                subplot_kw={'projection': ccrs.PlateCarree()},
                                figsize=(30, 15),facecolor='white') 
        fig.tight_layout()


        axs=axs.flatten()
        
#############################################################################################################################################################################################################
        
        #THIS IS VERY IMPORTANT you will multiply the "k" in the node = line by the largest value of the SOM so in the case of a 4x3 it will be multiplied by 4. For example,
        #if your SOM was an 8x5 you would multiple the k by 8.
        # not true, probably it must be multiplied by the som_col
#############################################################################################################################################################################################################

        for k in range(weights.shape[0]):
            for i in range(weights.shape[1]):
                #node = (k,i)
                node=(k*som_col)+i
                SOM_mslp = weights[k,i,:].reshape(nx,ny)
                SOM_mslp = SOM_mslp / norm_factor 
                
                # to check
                lev_start = SOM_mslp.min()
                print(lev_start)             
                lev_stop = SOM_mslp.max()
                print(lev_stop)
                
                # mslp
                #levs = np.arange(-15, 15, 1)
                lev_start = -10
                lev_step= 2
                levs = (np.arange(lev_start-(lev_step/2), np.abs(lev_start)+(lev_step/2)+lev_step,lev_step))
                cs2=axs[(k*som_col)+i].contourf(lon, lat, SOM_mslp,
                                  transform = ccrs.PlateCarree(),
                                  cmap='coolwarm', levels = levs,extend='both')
           
                # z500
                #levs = np.arange(-250, 280, 30)
                #cs2=axs[(k*som_col)+i].contourf(lon, lat, SOM_mslp,
                                  #transform = ccrs.PlateCarree(),
                                  #cmap=precip_colormap, levels = levs,extend='both')
                axs[(k*som_col)+i].set_extent([lon[0], lon[-1], lat[0], lat[-1]], ccrs.PlateCarree())

                axs[(k*som_col)+i].coastlines()
                axs[(k*som_col)+i].add_feature(cfeature.BORDERS) 
                #axs[(k*4)+i].scatter(-156.36,71.19, c='yellow',marker= 'o',s=120, linewidth=2,edgecolors= "black" ,zorder= 4,transform=datacrs)


                # Title each subplot 
                axs[(k*som_col)+i].set_title('Node:'+str(node+1) + " Freq:" + str(frequencies[k,i]), fontsize=18)


                plt.tight_layout()
                fig.subplots_adjust(bottom=0.25, top=0.9, left=0.05, right=0.6,
                            wspace=0.05, hspace=0.25)

        cbar_ax = fig.add_axes([0.08, 0.2, 0.5, 0.02])
        #cbar=fig.colorbar(cs2,cax=cbar_ax, ticks = np.arange(lev_start, np.abs(lev_start)+lev_step, lev_step*2),orientation='horizontal')
        cbar=fig.colorbar(cs2,cax=cbar_ax, ticks = levs,orientation='horizontal')

        cbar.set_label('Z500 (m)', fontsize=22)

        plt.suptitle('SOM Nodes: Z500 (m). '+name+'', x= 0.33 ,fontsize=22)   
        plt.savefig(folderpath + 'anomalyplot_'+name+'.png', bbox_inches='tight')
        plt.show()

#%%
duration = 1000 # milliseconds
freq = 440  # Hz
winsound.Beep(freq, duration)
