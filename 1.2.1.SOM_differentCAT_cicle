import os

os.chdir('C:\\Users\\Criss\\Documents\\Lavoro\\Assegno 2024_2025\\Codici')

#Imports 
import xarray as xr
import numpy as np
import pandas as pd
import warnings
import minisom
import pickle
from minisom import asymptotic_decay
import cartopy.mpl.ticker as cticker
from cartopy.util import add_cyclic_point
from mpl_toolkits.mplot3d import Axes3D
import matplotlib as mpl
from numpy import savetxt
from numpy import loadtxt
import cartopy
import cartopy.crs as ccrs
import cartopy.feature as cfeature
import glob
import matplotlib.pyplot as plt
import os
from itertools import product
import winsound
from datetime import date

#Functions Used in the Code
def getList(dict):
    list = []
    for key in dict.keys():
        list.append(key)
        
    return list
def sammon(x, n, display = 2, inputdist = 'raw', maxhalves = 20, maxiter = 500, tolfun = 1e-9, init = 'default'):

    import numpy as np 
    from scipy.spatial.distance import cdist

    """Perform Sammon mapping on dataset x
    y = sammon(x) applies the Sammon nonlinear mapping procedure on
    multivariate data x, where each row represents a pattern and each column
    represents a feature.  On completion, y contains the corresponding
    co-ordinates of each point on the map.  By default, a two-dimensional
    map is created.  Note if x contains any duplicated rows, SAMMON will
    fail (ungracefully). 
    [y,E] = sammon(x) also returns the value of the cost function in E (i.e.
    the stress of the mapping).
    An N-dimensional output map is generated by y = sammon(x,n) .
    A set of optimisation options can be specified using optional
    arguments, y = sammon(x,n,[OPTS]):
       maxiter        - maximum number of iterations
       tolfun         - relative tolerance on objective function
       maxhalves      - maximum number of step halvings
       input          - {'raw','distance'} if set to 'distance', X is 
                        interpreted as a matrix of pairwise distances.
       display        - 0 to 2. 0 least verbose, 2 max verbose.
       init           - {'pca', 'cmdscale', random', 'default'}
                        default is 'pca' if input is 'raw', 
                        'msdcale' if input is 'distance'
    The default options are retrieved by calling sammon(x) with no
    parameters.
    File        : sammon.py
    Date        : 18 April 2014
    Authors     : Tom J. Pollard (tom.pollard.11@ucl.ac.uk)
                : Ported from MATLAB implementation by 
                  Gavin C. Cawley and Nicola L. C. Talbot
    Description : Simple python implementation of Sammon's non-linear
                  mapping algorithm [1].
    References  : [1] Sammon, John W. Jr., "A Nonlinear Mapping for Data
                  Structure Analysis", IEEE Transactions on Computers,
                  vol. C-18, no. 5, pp 401-409, May 1969.
    Copyright   : (c) Dr Gavin C. Cawley, November 2007.
    This program is free software; you can redistribute it and/or modify
    it under the terms of the GNU General Public License as published by
    the Free Software Foundation; either version 2 of the License, or
    (at your option) any later version.
    This program is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU General Public License for more details.
    You should have received a copy of the GNU General Public License
    along with this program; if not, write to the Free Software
    Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
    """

    # Create distance matrix unless given by parameters
    if inputdist == 'distance':
        D = x
        if init == 'default':
            init = 'cmdscale'
    else:
        D = cdist(x, x)
        if init == 'default':
            init = 'pca'

    if inputdist == 'distance' and init == 'pca':
        raise ValueError("Cannot use init == 'pca' when inputdist == 'distance'")

    if np.count_nonzero(np.diagonal(D)) > 0:
        raise ValueError("The diagonal of the dissimilarity matrix must be zero")

    # Remaining initialisation
    N = x.shape[0]
    scale = 0.5 / D.sum()
    D = D + np.eye(N)     
    if np.count_nonzero(D<=0) > 0:
        raise ValueError("Off-diagonal dissimilarities must be strictly positive")   

    Dinv = 1 / D
    if init == 'pca':
        [UU,DD,_] = np.linalg.svd(x)
        y = UU[:,:n]*DD[:n] 
    elif init == 'cmdscale':
        from cmdscale import cmdscale
        y,e = cmdscale(D)
        y = y[:,:n]
    else:
        y = np.random.normal(0.0,1.0,[N,n])
    one = np.ones([N,n])
    d = cdist(y,y) + np.eye(N)
    dinv = 1. / d
    delta = D-d 
    E = ((delta**2)*Dinv).sum() 

    # Get on with it
    for i in range(maxiter):

        # Compute gradient, Hessian and search direction (note it is actually
        # 1/4 of the gradient and Hessian, but the step size is just the ratio
        # of the gradient and the diagonal of the Hessian so it doesn't
        # matter).
        delta = dinv - Dinv
        deltaone = np.dot(delta,one)
        g = np.dot(delta,y) - (y * deltaone)
        dinv3 = dinv ** 3
        y2 = y ** 2
        H = np.dot(dinv3,y2) - deltaone - np.dot(2,y) * np.dot(dinv3,y) + y2 * np.dot(dinv3,one)
        s = -g.flatten(order='F') / np.abs(H.flatten(order='F'))
        y_old    = y

        # Use step-halving procedure to ensure progress is made
        for j in range(maxhalves):
            s_reshape = np.reshape(s, (-1,n),order='F')
            y = y_old + s_reshape
            d = cdist(y, y) + np.eye(N)
            dinv = 1 / d
            delta = D - d
            E_new = ((delta**2)*Dinv).sum()
            if E_new < E:
                break
            else:
                s = 0.5*s

        # Bomb out if too many halving steps are required
        if j == maxhalves-1:
            print('Warning: maxhalves exceeded. Sammon mapping may not converge...')

        # Evaluate termination criterion
        if abs((E - E_new) / E) < tolfun:
            if display:
                print('TolFun exceeded: Optimisation terminated')
            break

        # Report progress
        E = E_new
        if display > 1:
            print('epoch = %d : E = %12.10f'% (i+1, E * scale))

    if i == maxiter-1:
        print('Warning: maxiter exceeded. Sammon mapping may not have converged...')

    # Fiddle stress to match the original Sammon paper
    E = E * scale
    
    return [y,E]

# COLORMAP
new_colormap = [
    "#ecf5ff",     # celeste pi√π chiaro
   # "#d9ecff",    #new
    "#a1cff7",    #new
    "#5ca8e5",    #new
    "#2476b5",    #new
    "#0c4b78",    #new
    "#00334c",    #new
    "#005259",    #new
    "#008c69",    #new
    "#00cc44",
    "#95ff00",
    "#ffff00",
    "#ffd400",
    "#ffaa00",
    "#ff7f00",
    "#ff5500",
    "#ff2a00",
    "#f20c1f",
    "#cc1461",
    "#eb1cb7",    #new
    "#be21cc",
    "#8613bf",
    "#5f19a6",
    "#330067",    #new
]

precip_colormap = mpl.colors.ListedColormap(new_colormap)

#%% Dataset and Export location

#State the path where the file is located. This will be the same path used in MiniSOM Tutorial Step #1
PATH ="C:/Users/Criss/Documents/Lavoro/Assegno 2024_2025/Codici/SOM/" #This is the path where the data files
folderpath = 'C:/Users/Criss/Documents/Lavoro/Assegno 2024_2025/Codici/SOM/SOMs_output/'  #The output SOMs will be stored in a seperate folder. This will need to be changed to the User's specific path and folder name

today = date.today()

#You want to change these to the settings that you would like. 
som_col = 5
som_row = 2
min_som = min(som_col, som_row)
#x= 3 #columns
#y= 4 #row
#sigma = min_som -1        #The sigma value must be y-1. 
sigma = 1
#learning_rate = 0.005  #Learning Rate 
#learning_rate = 0.008

q_win = 100000.
number_iterations = 100000
number_of_soms = 5

#best LR 0.008 ?
learning_rate_list = [0.0001, 0.0005, 0.001, 0.003, 0.005, 0.007, 0.008, 0.009, 0.01, 0.02, 0.03, 0.04, 0.05, 0.1, 0.5, 1]

#sigma_list=[0.05, 0.1, 0.2, 0.5, 0.6, 0.7, 0.8, 0.9, 1]
#sigma_list=[0.05, 0.2, 0.5, 0.6, 0.8, 1.0, 1.2, 1.5, 1.6, 1.8, 2]
#sigma_list=[1.]
#%% CHANGEE
variable_list = learning_rate_list
#%%
mean_qerror_list_cat = [ [None for _ in range(len(variable_list)) ] for i in range(3)]
mean_topoerror_list_cat = [ [None for _ in range(len(variable_list)) ] for i in range(3)]




for param in range(len(variable_list)):
    learning_rate = variable_list[param]
    #sigma = variable_list[param]
    qerror_list_cat = []
    topoerror_list_cat = []
    print("learning rate:" + str(learning_rate))
    
    for n in range(3):
        qerror_list = []
        topoerror_list = []
        
        catn = n + 1
        print("CAT" + str(catn) + ": ")
        print(" charact. of the SOM:")
        print("  " + str(som_col) + "by" + str(som_row) + "       n_iter.:" + str(number_iterations))
        print("  LR:" + str(learning_rate) + "  sig:" + str(sigma))
        
        data_train = np.load(PATH + 'TEST2_som_data_train_CAT'+ str(catn) + 'norm.npy')
        time_values = np.load(PATH +'TEST2_som_time_data_CAT'+ str(catn) + 'norm.npy')
        z_raw = xr.open_dataset(PATH + 'VER2_SOM_Z_raw_CAT'+ str(catn) + 'norm.nc')
        print(data_train.shape)
        len_datatrain = len(data_train[0])
        input_length = len_datatrain #This is value is the the length of the latitude X longitude. It is the second value in the data_train.shape step. 
        
        # variable loading
        #z_values = z_raw['Z'].values
        #z_SOM = z_raw['Z']
        lon = z_raw['lon'].values
        lat = z_raw['lat'].values
        nx = int((z_raw['lat'].size))
        ny = int((z_raw['lon'].size))
        ndays =int((z_raw['time'].size))
        
        norm_factor = [0.10014513220331027, 0.10251989701956438, 0.1285688367470829]
        norm_factor = norm_factor[n]
        
        som_names = "  SOM_CAT"+ str(catn) + "_" + str(today) + "_" + str(som_col) + "by" + str(som_row) + "_LR" + str(learning_rate) + "_sig" + str(sigma) + "_iter" + str(number_iterations) +  "_n_"
        print(som_names)
        
        # generate the soms
        for i in range(number_of_soms):   #The number of SOMs that will be generated. 
            # initialize random weights
            era5_hourly_som1 = minisom.MiniSom(som_row, som_col, input_len = input_length, sigma = sigma, learning_rate=learning_rate, neighborhood_function='gaussian', decay_function = asymptotic_decay)
            era5_hourly_som1.random_weights_init(data_train)
            # train som
            era5_hourly_som1.train(data_train, num_iteration= number_iterations,random_order=True, verbose=True)
            q_error = era5_hourly_som1.quantization_error(data_train)
            
            #Add the details of the SOM settings into the name of the file so that you know what the SOM is showing.
            with open(folderpath + som_names +str(i+1)+'.p', 'wb') as outfile: #this is how you save the file, the str(i) is a unique name
                pickle.dump(era5_hourly_som1, outfile)
            weights = era5_hourly_som1._weights
            qerror_list += [q_error]
            i+=1
            if q_error < q_win:
                q_win = q_error
                win_weights = era5_hourly_som1
        
        qerror_list_cat += [qerror_list]

        print('\007')
        
        names = ([os.path.splitext(os.path.split(x)[-1])[0] for x in glob.glob(folderpath + som_names + '*')]) #this might be different for you

        #but this is just grabbing the first few characters of my names of my file (see above how I named them, for example som_8)

        filepaths = glob.glob(folderpath + som_names + '*')  #this is showing the path and the given file

        print(names)
        
        for path, name in zip(filepaths, names):
            with open (path, 'rb') as f:
                file = pickle.load(f) #This is loading every single som in that location
                frequencies = file.activation_response(data_train) #this is grabbing each freq
                q_error = round(file.quantization_error(data_train),3) #this is grabbing every q error out to 3 decimal places
                topo_error = round(file.topographic_error(data_train),6) #this is grabbing ever topographic error out to 3 decimal places
                print(topo_error)
                topoerror_list += [topo_error]
                
                plt.figure(figsize=(10,8))
                cs = plt.pcolormesh(frequencies, cmap='Blues')
                plt.title(name + ' ' + 'Freq.,' + ' ' + 'QE =' + ' ' f"{q_error}" + ' ' + 'TE =' + ' ' f"{topo_error}", fontsize=12)

                #in the title, I am plotting every q error and topo error from each som. You need to have the f" in front and whatever variable in {}
                #And this ' ' represents a space in the title
                plt.colorbar(cs)
                plt.ylim(som_row,0) # Change the 3 to whatever size SOM you have (this is the 2nd number)
                plt.tight_layout()
                #plt.savefig(folderpath + 'frequencies_'+name+'.png') #I am saving the outputs as a png file in the same file path and giving it the name of each SOM
                
                plt.show()
                
                [y,E] = sammon(file.get_weights().reshape(som_col*som_row, input_length),2,display=1)

                    # Plot Sammon map nodes
                plt.figure(figsize=(10,8))
                plt.scatter(y[:,0], y[:,1], s=20, c='black', marker='o')

                    # Add lines between nodes
                mslp = np.reshape(y,(som_row,som_col,2))
                len_x, len_y, len_z = mslp.shape

                # add vertical lines
                for i in range(len_x-1):
                    for j in range(len_y):
                        plt.plot(mslp[i:i+2,j,0],mslp[i:i+2,j,1],c='black')

                # add horizontal lines
                for i in range(len_x):
                    for j in range(len_y-1):
                        plt.plot(mslp[i,j:j+2,0],mslp[i,j:j+2,1],c='black')  

                plt.xticks([])
                plt.yticks([])
                plt.title(name, fontsize=12)
                plt.savefig(folderpath + 'sammonplot_'+name+'.png') #I am saving the outputs as a png file in the same file path and giving it the name of each SOM

                plt.show()
                
        topoerror_list_cat += [topoerror_list]
        
        print('\007')

    
        for path, name in zip(filepaths, names):
            with open (path, 'rb') as f:
                som = pickle.load(f)
                weights = som._weights
    
                #Need to create a new dictionary for the new data
                keys = [i for i in product(range(som_row), range(som_col))]  ## DIM OF SOMS
                winmap = {key: [] for key in keys}
    
                for i, x in enumerate(data_train):
                    winmap[som.winner(x)].append(i)
                    som_keys = getList(winmap)
                frequencies = som.activation_response(data_train)
                datacrs = ccrs.PlateCarree()
                
                #You will set this to the dimensions of the SOM.  ## DIM OF SOMS
                fig, axs = plt.subplots(nrows=som_row,ncols=som_col, 
                                        subplot_kw={'projection':ccrs.LambertConformal(central_longitude=lon.mean(), central_latitude=lat.mean(), standard_parallels=(30, 60))},
                                        figsize=(30, 15),facecolor='white') 
                fig.tight_layout()
    
    
                axs=axs.flatten()
                
        #############################################################################################################################################################################################################
                
                #THIS IS VERY IMPORTANT you will multiply the "k" in the node = line by the largest value of the SOM so in the case of a 4x3 it will be multiplied by 4. For example,
                #if your SOM was an 8x5 you would multiple the k by 8.
                # not true, probably it must be multiplied by the som_col
        #############################################################################################################################################################################################################
                
                for k in range(weights.shape[0]):
                    for i in range(weights.shape[1]):
                        #node = (k,i)
                        node=(k*som_col)+i
                        SOM_mslp = weights[k,i,:].reshape(nx,ny)
                        SOM_mslp = SOM_mslp / norm_factor
                        #levs = np.arange(-10, 10, 2)
                        #lev_start = -12
                        #lev_step= 2
                        #levs = (np.arange(lev_start-(lev_step/2), np.abs(lev_start)+(lev_step/2)+lev_step,lev_step))
                        lev_start = SOM_mslp.min()
                        #print(lev_start)
                        lev_step= 200
                        
                        lev_stop = SOM_mslp.max()
                        #print(lev_stop)
                        levs = np.arange(5200, 5920, 30)
                        #levs = (np.arange(lev_start-(lev_step/2), np.abs(lev_start)+(lev_step/2)+lev_step,lev_step))
                        cs2=axs[(k*som_col)+i].contourf(lon, lat, SOM_mslp,
                                          transform = ccrs.PlateCarree(),
                                          cmap=precip_colormap, levels = levs,extend='both')
                        axs[(k*som_col)+i].set_extent([lon[0], lon[-1], lat[0], lat[-1]], ccrs.PlateCarree())
    
                        axs[(k*som_col)+i].coastlines()
                        axs[(k*som_col)+i].add_feature(cfeature.BORDERS) 
                        #axs[(k*4)+i].scatter(-156.36,71.19, c='yellow',marker= 'o',s=120, linewidth=2,edgecolors= "black" ,zorder= 4,transform=datacrs)
    
    
                        # Title each subplot 
                        axs[(k*som_col)+i].set_title('Node:'+str(node+1) + " Freq:" + str(frequencies[k,i]), fontsize=18)
    
    
                        plt.tight_layout()
                        fig.subplots_adjust(bottom=0.25, top=0.9, left=0.05, right=0.6,
                                    wspace=0.05, hspace=0.25)
    
                cbar_ax = fig.add_axes([0.08, 0.2, 0.5, 0.02])
                #cbar=fig.colorbar(cs2,cax=cbar_ax, ticks = np.arange(lev_start, np.abs(lev_start)+lev_step, lev_step*2),orientation='horizontal')
                cbar=fig.colorbar(cs2,cax=cbar_ax, ticks = levs,orientation='horizontal')
    
                cbar.set_label('Z500 (m)', fontsize=22)
    
                plt.suptitle('SOM Nodes: Z500 (m). '+name+'', x= 0.33 ,fontsize=22)   
                plt.savefig(folderpath + 'plot '+name+'.png', bbox_inches='tight')
                plt.show()
                
        print ("End CAT" + str(catn))
        
    mean_qerror_list_cat[0][param] = np.mean(qerror_list_cat[0])
    mean_qerror_list_cat[1][param] = np.mean(qerror_list_cat[1])
    mean_qerror_list_cat[2][param] = np.mean(qerror_list_cat[2])

    mean_topoerror_list_cat[0][param] = np.mean(topoerror_list_cat[0])
    mean_topoerror_list_cat[1][param] = np.mean(topoerror_list_cat[1])
    mean_topoerror_list_cat[2][param] = np.mean(topoerror_list_cat[2])

duration = 2000 # milliseconds
freq = 440  # Hz
winsound.Beep(freq, duration)
    
print("THE END")
#%%    
#list_values having strings  
#learning_rate_list
QE_CAT1 = mean_qerror_list_cat[0]
QE_CAT2 = mean_qerror_list_cat[1]
QE_CAT3 = mean_qerror_list_cat[2]

TE_CAT1 = mean_topoerror_list_cat[0]
TE_CAT2 = mean_topoerror_list_cat[1]
TE_CAT3 = mean_topoerror_list_cat[2]
#%%
# LEARNING RATE
dict = {'Learning Rate':learning_rate_list, 'QE CAT1':QE_CAT1, 'QE CAT2':QE_CAT2, 'QE CAT3':QE_CAT3, 'TE CAT1':TE_CAT1, 'TE CAT2':TE_CAT2, 'TE CAT3':TE_CAT3}  
# SIGMA
#dict = {'Sigma':sigma_list, 'QE CAT1':QE_CAT1, 'QE CAT2':QE_CAT2, 'QE CAT3':QE_CAT3, 'TE CAT1':TE_CAT1, 'TE CAT2':TE_CAT2, 'TE CAT3':TE_CAT3}  
df = pd.DataFrame(dict)  
print(df)  

df.to_csv(folderpath + "QE_TE_variable_LR_" + str(som_col) + "by" + str(som_row) + ".csv", index=False)
#df.to_csv(folderpath + "QE_TE_variable_sigma_" + str(som_col) + "by" + str(som_row) + "2.csv", index=False)


#%%

fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12,6))
fig.suptitle("Variable LR:" + str(som_col) + "by" + str(som_row) + "  sig." + str(sigma) + "  n iter." + str(number_iterations), size=15)
#fig.suptitle("Variable sigma:" + str(som_col) + "by" + str(som_row) + "  LR" + str(learning_rate) + "  n iter." + str(number_iterations), size=15)
ax1.plot(learning_rate_list, QE_CAT1, label="CAT1", linestyle = "--", marker = "o", markersize = 5)
ax1.plot(learning_rate_list, QE_CAT2, label="CAT2", linestyle = "--", marker = "o", markersize = 5)
ax1.plot(learning_rate_list, QE_CAT3, label="CAT3", linestyle = "--", marker = "o", markersize = 5)
ax1.set_xscale("log")
ax1.set_title("QE error")
#ax1.set_xlabel("sigma")
ax1.set_xlabel("Learning rate")
ax1.set_ylabel("error")
ax1.legend()

ax2.plot(learning_rate_list, TE_CAT1, label="CAT1", linestyle = "--", marker = "o", markersize = 5)
ax2.plot(learning_rate_list, TE_CAT2, label="CAT2", linestyle = "--", marker = "o", markersize = 5)
ax2.plot(learning_rate_list, TE_CAT3, label="CAT3", linestyle = "--", marker = "o", markersize = 5)
ax2.set_xscale("log")
ax2.set_title("TE error")
#ax2.set_xlabel("sigma")
ax2.set_xlabel("Learning rate")
#ax2.set_ylabel("TE")
ax2.legend()
plt.savefig(folderpath + "QE_TE_variable_LR_" + str(som_col) + "by" + str(som_row) + "_1")

#%%

fig, ((ax1, ax2), (ax3, ax)) = plt.subplots(2, 2, figsize=(10,10))
fig.suptitle("Variable LR:" + str(som_col) + "by" + str(som_row) + "  sig." + str(sigma) + "  n iter." + str(number_iterations), size=15)
#fig.suptitle("Variable sigma:" + str(som_col) + "by" + str(som_row) + "  LR" + str(learning_rate) + "  n iter." + str(number_iterations), size=15)
ax1.plot(variable_list, QE_CAT1, label="CAT1", linestyle = "--", marker = "o", markersize = 5)
ax1.set_title("QE error - CAT1")
ax1.set_xscale("log")
#ax1.set_xlabel("sigma")
ax1.set_xlabel("Learning rate")
ax1.set_ylabel("error")
ax1.legend()


ax2.plot(variable_list, QE_CAT2, label="CAT2", linestyle = "--", marker = "o", markersize = 5, color="orange")
ax2.set_xscale("log")
ax2.set_title("QE error - CAT2")
#ax2.set_xlabel("sigma")
ax2.set_xlabel("Learning rate")
#ax2.set_ylabel("error")
ax2.legend()


ax3.plot(variable_list, QE_CAT3, label="CAT3", linestyle = "--", marker = "o", markersize = 5, color="green")
ax3.set_title("QE error - CAT3")
ax3.set_xscale("log")
#ax3.set_xlabel("sigma")
ax3.set_xlabel("Learning rate")
ax3.set_ylabel("error")
ax3.legend()

ax.plot(variable_list, TE_CAT1, label="CAT1", linestyle = "--", marker = "o", markersize = 5)
ax.plot(variable_list, TE_CAT2, label="CAT2", linestyle = "--", marker = "o", markersize = 5)
ax.plot(variable_list, TE_CAT3, label="CAT3", linestyle = "--", marker = "o", markersize = 5)
ax.set_xscale("log")
ax.set_title("TE error")
#ax.set_xlabel("sigma")
ax.set_xlabel("Learning rate")
#ax2.set_ylabel("TE")
ax.legend()
   
plt.tight_layout() 
plt.savefig(folderpath + "QE_TE_variable_LR_" + str(som_col) + "by" + str(som_row) + "_2")
#plt.savefig(folderpath + "QE_TE_variable_sigma_" + str(som_col) + "by" + str(som_row) + "_3")
